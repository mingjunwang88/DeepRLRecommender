{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "071e2241-e33f-4634-b067-b4a20bee8715",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch as t\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ced7d276-0001-480a-b790-1421f9881f8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Actor(nn.Module):\n",
    "  ###########################################################################\n",
    "  # This is a generic action function out out a array which can be used as a output for \n",
    "  #  1:DDPG for futher processing \n",
    "  #  2:discrete actions for further softmax\n",
    "  ###########################################################################\n",
    "  def __init__(self, dim_state, dim_action, alpha, checkpoint='actor.pt', num_layers=2):\n",
    "    super(Actor, self).__init__()\n",
    "    self.alpha = alpha\n",
    "    self.checkpoint = checkpoint\n",
    "    \n",
    "    layers = []\n",
    "    for i in range(num_layers):\n",
    "      layers.append(dim_state // 2**i)\n",
    "    #print(layers)\n",
    "    blocks=[self.block(i,j) for i, j in zip(layers[0:-1], layers[1:])]\n",
    "    self.total_mc = nn.Sequential(*blocks)    \n",
    "    self.linear = nn.Linear(layers[-1], dim_action)\n",
    "    self.optimizer = optim.Adam(self.parameters(), lr = alpha, weight_decay=1e-4)\n",
    "    self.to(device)\n",
    "    \n",
    "  def saveChk(self):\n",
    "    print('save model...')\n",
    "    t.save(self.state_dict(), self.checkpoint)\n",
    "    \n",
    "  def loadChk(self):\n",
    "    print('load model')\n",
    "    self.load_state_dict(t.load(self.checkpoint))\n",
    "    \n",
    "  def block(self, dim_in, dim_out):\n",
    "    return nn.Sequential(\n",
    "    nn.Linear(dim_in, dim_out),\n",
    "    nn.ReLU()\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    output = x.to(device)\n",
    "    \n",
    "    output = self.total_mc(output)\n",
    "    output = self.linear(output)\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e341197d-9562-4156-967f-48334660fff6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "  def __init__(self, dim_state, dim_action, alpha, checkpoint='critic.pt',num_layers=2):\n",
    "    super(Critic, self).__init__()\n",
    "    self.checkpoint = checkpoint\n",
    "    self.alpha = alpha\n",
    "    \n",
    "    layers = []\n",
    "    for i in range(num_layers):\n",
    "      layers.append((dim_state+dim_action) // 2**i)\n",
    "    \n",
    "    total_blocks = [self.blocks(i,j) for i,j in zip(layers[0:-1],layers[1:])]\n",
    "    print(total_blocks)\n",
    "    \n",
    "    self.total_fc = nn.Sequential(*total_blocks)\n",
    "    self.linear=nn.Linear(layers[-1], 1)\n",
    "    self.optimizer = optim.Adam(self.parameters(), lr=alpha, weight_decay=1e-4)\n",
    "    self.to(device)\n",
    "      \n",
    "  def blocks(self, dim_in, dim_out):\n",
    "    return nn.Sequential(\n",
    "    nn.Linear(dim_in, dim_out),\n",
    "    nn.ReLU()\n",
    "    )\n",
    "  \n",
    "  def saveChk(self):\n",
    "    print('save model...')\n",
    "    t.save(self.state_dict(), self.checkpoint)\n",
    "  \n",
    "  def loadChk(self):\n",
    "    print('load model...')\n",
    "    self.load_state_dict(t.load(self.checkpoint))\n",
    "  \n",
    "  def forward(self, state, action):\n",
    "    state = state.to(device)\n",
    "    action = action.to(device)\n",
    "    \n",
    "    output = self.total_fc(t.cat((state, action), dim=1))\n",
    "    output = self.linear(output)\n",
    "    return output \n",
    "#critic = Critic(50, 50, 1e-4, checkpoint='critic.pt',num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b02600bc-f243-4360-b22d-2f008395bd73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Simulator class\n",
    "class RecModel(nn.Module):\n",
    "  def __init__(self, dim_input, layers):\n",
    "    super(RecModel, self).__init__()\n",
    "    \n",
    "    layer_list = []\n",
    "    for i in range(layers):\n",
    "      layer_list.append(dim_input // 2**i)\n",
    "    print('layers: ', layer_list)\n",
    "    \n",
    "    total_blocks=[self.block(i,j) for i,j in zip(layer_list[:-1],layer_list[1:])]\n",
    "    self.total_mc = nn.Sequential(*total_blocks)\n",
    "    self.linear = nn.Linear(layer_list[-1], 1)\n",
    "    self.to(device)\n",
    "  \n",
    "  def block(self, dim_in, dim_out):\n",
    "    return nn.Sequential(\n",
    "      nn.Linear(dim_in, dim_out),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out= x.to(device)\n",
    "    #print(out.dtype, out.type())\n",
    "    \n",
    "    out = self.total_mc(out.float())  #use t.tensor(np) will return torch.DoubleTensor, need to convert to float\n",
    "    out = self.linear(out)\n",
    "    out = t.sigmoid(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d505dee1-819e-4711-a533-b486171d62b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Build the env compatible with Rllib\n",
    "import gym\n",
    "from gym.spaces import Box, Discrete\n",
    "\n",
    "class Env(gym.Env):\n",
    "  \n",
    "  self.getStateActions(states, actions)\n",
    "  self.getSimulator(simulator)\n",
    "  \n",
    "  def __init__(self, cofig):\n",
    "    #Two required class members  \n",
    "    high = 1000* np.ones(50)\n",
    "    low = -high\n",
    "    \n",
    "    self.action_space = Box(high=high, low=low)\n",
    "    self.observation_space = Box(high=high, low=low)\n",
    "    \n",
    "    self.state=None\n",
    "    self.t = 0\n",
    "  \n",
    "  def getStateActions(self,states, actions):\n",
    "    self.states = states\n",
    "    self.actions = actions\n",
    "    \n",
    "  def getSimulator(self,simulator):\n",
    "    self.simulator = simulator\n",
    "  \n",
    "  def reset(self):\n",
    "    self.state = self.states[self.n]\n",
    "    self.n+=1\n",
    "    \n",
    "    self.step = 0\n",
    "    return self.state\n",
    "  \n",
    "  def step(self, action):\n",
    "    #need to return state, reward, done, info\n",
    "    prob = self.simulator(t.cat((t.tensor(self.state).float(), t.tensor(action).float())))\n",
    "    if prob.item()>=0.5:\n",
    "      reward =1\n",
    "      state_new = self.state + action\n",
    "    else:\n",
    "      reward = 0\n",
    "      state_new = state\n",
    "    self.step+=1\n",
    "    done = (self.step==1000)\n",
    "    \n",
    "    self.state = state_new\n",
    "    return state, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a1dfd047-3633-4e8a-9ebe-927f63276e73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class replayBuffer():\n",
    "  \n",
    "  ################################################\n",
    "  #The buffer should include s1, a1, r1, s2, done\n",
    "  ################################################\n",
    "  \n",
    "  def __init__(self, maxm_size,dim_state, dim_action):\n",
    "    self.counter = 0\n",
    "    self.state_mem = np.zeros((maxm_size, dim_state))\n",
    "    self.action_mem = np.zeros((maxm_size, dim_action))\n",
    "    self.reward_mem = np.zeros(maxm_size)\n",
    "    self.state_next_mem = np.zeros((maxm_size,dim_state))\n",
    "    self.done_mem = np.zeros(maxm_size)\n",
    "    self.maxm_size = maxm_size\n",
    "    \n",
    "  def store_transaction(self,s1, a1, r1, s2, done):\n",
    "    index = self.counter % self.maxm_size\n",
    "    \n",
    "    self.state_mem[index] = s1\n",
    "    self.action_mem[index] = a1\n",
    "    self.reward_mem[index] = r1\n",
    "    self.state_next_mem[index] = s2\n",
    "    self.done_mem[index] = done\n",
    "    \n",
    "    self.counter+=1\n",
    "    \n",
    "  def sample_batch(self, batch_size=16):\n",
    "    maxm_s = min(self.counter, self.maxm_size)\n",
    "    batch = np.random.choice(maxm_s, batch_size)\n",
    "    \n",
    "    state_batch = self.state_mem[batch]\n",
    "    action_batch = self.action_mem[batch]\n",
    "    reward_batch = self.reward_mem[batch]\n",
    "    state_next_batch=self.state_next_mem[batch]\n",
    "    done_batch = self.done_mem[batch]\n",
    "    \n",
    "    return state_batch, action_batch, reward_batch, state_next_batch, done_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4bf0a024-6bce-4373-b095-1d7fe5beffaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ActorCriticSimulator",
   "notebookOrigID": 966441684062225,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
